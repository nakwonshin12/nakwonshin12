# 머신러닝 day2 20210511

### 여는 생각

- AI를 통한교육
    - 개인화된 교육을 설계한다면 무엇이 중요한가.

        각 항목별로 세분화해서 시스템을 짜야 한다. 

        (사실상 AI가 아니더라도 학습프로그램을 잘 설계하면 전문화된 교육이 가능하다.  

        - 이 문제들을 맞은 사람의 공부 성향
        - 이 항목들을 틀린 사람들의 공부 성향

[https://m.blog.naver.com/PostView.nhn?blogId=samsjang&logNo=220965998073&proxyReferer=https:%2F%2Fwww.google.com%2F](https://m.blog.naver.com/PostView.nhn?blogId=samsjang&logNo=220965998073&proxyReferer=https:%2F%2Fwww.google.com%2F)

![%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20day2%2020210511%20080df4d9d37b4dd59ab0c52fe30486d4/Untitled.png](%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20day2%2020210511%20080df4d9d37b4dd59ab0c52fe30486d4/Untitled.png)

![%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20day2%2020210511%20080df4d9d37b4dd59ab0c52fe30486d4/Untitled%201.png](%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20day2%2020210511%20080df4d9d37b4dd59ab0c52fe30486d4/Untitled%201.png)

![%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20day2%2020210511%20080df4d9d37b4dd59ab0c52fe30486d4/Untitled%202.png](%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20day2%2020210511%20080df4d9d37b4dd59ab0c52fe30486d4/Untitled%202.png)

- sklearn으로 knn분류하기
    - 예제1

        ![%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20day2%2020210511%20080df4d9d37b4dd59ab0c52fe30486d4/Untitled%203.png](%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20day2%2020210511%20080df4d9d37b4dd59ab0c52fe30486d4/Untitled%203.png)

        ```python
        from sklearn.neighbors import KNeighborsClassifier
        from sklearn.model_selection import train_test_split, cross_val_score

        x_train, x_test, y_train, y_test = train_test_split(X, y, random_state =30)  #

        cvs = []
        for k in range(5, 20):
            clf = KNeighborsClassifier(n_neighbors=k)                                           # 1. knn분류와 k를 정의한다. 
            clf.fit(x_train, y_train)                                                           # 2. 데이터 학습시킨다.(데이터와 라벨 전달)
            prediction = clf.predict(x_test)                                                    # 3. 새로운데이터를 학습한다. 
            print("+++++++ k = {}+++++++++".format(k))  
            print("clf.score                  :{0:3f}".format(clf.score(x_train, y_train)))     #4. 학습된 데이터의 정확도를 측정한다.
            print("(pred  ==  y_test)score    :{0:3f}".format((prediction == y_test).mean()))
                                                                                               #에측한 결과값과 답안지 label를 비교
                                                                                               #True 1/ False 0 으로 평균값을 계산
            scre = cross_val_score(clf, X, y, cv=10).mean()  #교차검증(피자10조각) 평균치
            cvs.append((k,scre))
            print("cross_val_score            :{0:3f}".format(scre))
            
        #데이터 조각 10개로 나눠서 평균치를 냄 각각의 데이터셋의 균등분할 테스트

        #학습참여한 데이터 98%
        #테스트 데이터: 92%
        #평균적으로 96% 맞추더라...

        #테스트 데이터셋이 평균보다 안맞는 데이터들만 모여 있는 것
        ```

        ```python
        #모델 임포트
        from sklearn import KNeighborsClassifier
        from sklearn.model_selection import cross_val_score, train_test_split

        #데이터 분류
        x_train, x_test, y_train, y_test = train_test_split(X,y,random_state = 30)

        #모델, k 값 선언
        clf = KneighborsClassifier(n_neighbors = k)

        #데이터 학습, 정확도 평가
        clf.fit(x_train, y_train)
        clf.score(x_train, y_train)

        #새로운 데이터 분류 / 평가
        clf.predict(x_test) == y_test.mean()

        #교차검증
        cross_val_score(clf, X, y, cv=10).mean()
        ```

        ![%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20day2%2020210511%20080df4d9d37b4dd59ab0c52fe30486d4/Untitled%204.png](%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20day2%2020210511%20080df4d9d37b4dd59ab0c52fe30486d4/Untitled%204.png)

    - 예제2

        ```python
        import numpy as np
        diabt = np.loadtxt("C:\\workshop\\datasets\\diabetes.csv",
                           delimiter=',', skiprows=1)  #칼럼 값은 스킵힌다. 
        print(diabt)
        ```

        ```python
        #데이터와 라벨을 분류한다. 
        data = diabt[:,:-1]
        label = diabt[:,-1]
        print(data.shape, label.shape)
        ```

        ```python
        #모델 임포트
        from sklearn.neighbors import KNeighborsClassifier
        from sklearn.model_selection import train_test_split, cross_val_score

        #데이터분류
        x_train, x_test, y_train, y_test = train_test_split(data, label, random_state=30)
        ```

        ```python
        #k값은 통상적으로 학습데이타의 제곱근을 쓴다. 
        k = int(np.sqrt(x_train.shape[0]))
        print(k)
        ```

        ```python
        #구한 k값을 함수에 넣어서 코드를 실행한다. 
        knn = KNeighborsClassifier(n_neighbors=k)
        knn.fit(x_train, y_train)
        prediction = knn.predict(x_test)

        #새로운 데이터 분류 정확도 평균
        (prediction == y_test).mean()

        #그래프에서 해석한 것이 무엇인지 모르겠다.ㅜ
        import matplotlib.pyplot as plt
        plt.boxplot(data[:,0])
        plt.show()
        plt.boxplot(data[:,4])
        plt.show()

        ```

        ![%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20day2%2020210511%20080df4d9d37b4dd59ab0c52fe30486d4/Untitled%205.png](%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20day2%2020210511%20080df4d9d37b4dd59ab0c52fe30486d4/Untitled%205.png)

        ![%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20day2%2020210511%20080df4d9d37b4dd59ab0c52fe30486d4/Untitled%206.png](%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20day2%2020210511%20080df4d9d37b4dd59ab0c52fe30486d4/Untitled%206.png)

        ![%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20day2%2020210511%20080df4d9d37b4dd59ab0c52fe30486d4/Untitled%207.png](%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20day2%2020210511%20080df4d9d37b4dd59ab0c52fe30486d4/Untitled%207.png)

        ![%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20day2%2020210511%20080df4d9d37b4dd59ab0c52fe30486d4/Untitled%208.png](%E1%84%86%E1%85%A5%E1%84%89%E1%85%B5%E1%86%AB%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20day2%2020210511%20080df4d9d37b4dd59ab0c52fe30486d4/Untitled%208.png)